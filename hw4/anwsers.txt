*logs of all programs contain the node names which are omited in the results included in this file.
*Please see the log files if needed.

1.The pingpong program was run with 24 processes on 24 nodes. The latency and bandwidth are:
    pingpong latency: 8.613620e-04 ms
    pingpong bandwidth: 1.235480e+01 GB/s

2. 
int_ring:
    The final message is 2760000
    Time elapsed is 0.259854 s for 10000 loops among 24 processes
    Latency is 0.001083 ms.

    24 processes were on 24 different nodes.
    Because 2760000 == (0+23)*24/2*10000, correctness is checked.

array_ring:
    Time elapsed is 3.874143 s for 1000 loops among 24 processes
    Bandwidth is 12.389837 GB/s.
    *The correctness was also checked in tests with the value of the accumulative message but the line is commented out in the final version.

3. I chose to do the MPI version of scan. In my code, proc 0 does a sequential scan first fore reference.
Then, an MPI parallel version of scan is executed and timed.

    I followed the instructions. I first created a randomized long vector in proc 0 and use scatter to distribute to all procs.
    After a local scan of each proc's slice, allgather was used to share the last term of the result of every local scan with every proc.
    Offset is calculated and then added to the local result for every proc.
    Finally, proc 0 gathers the local scans and keep the scan of the whole vector.

    Rank 2/4 running on cs379.nyu.cluster.
    Rank 1/4 running on cs378.nyu.cluster.
    Rank 3/4 running on cs380.nyu.cluster.
    Rank 0/4 running on cs377.nyu.cluster.
    error = 0
    sequential-scan = 0.192729s
    parallel-scan   = 0.438670s

    I used 4 procs on 4 nodes. Error is checked for correctness. Because of the communication cost, the parallel version appear to be slower.

4.  For the final project, I will take the 'Parallel partitioning of large point clouds using an adaptive octree' in the given list.
    I had research experience working with point clouds generated by lidars for automobiles at a higher level.
    I think implementing the parallel partitioning algorithm at low level can echo with my past research.
    I plan to do it alone. I have read a few papers about the method of adaptive octree.
    I plan to use the point clouds in the KITTI dataset which I used for my past research (if they are large enough).
    The goal/evaluation metric is to partition the point cloud so that each container holds roughly the same number of points.
    I plan to parallelize the algorithm with openmp.